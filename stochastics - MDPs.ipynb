{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import poisson\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)\n",
    "\n",
    "State space $S \\in (0,1,2,3,4)$, representing the amount of items on hand\n",
    "\n",
    "Action space $A \\in (0,1,2,3,4)$, representing the amount of items to be ordered at the end of the day\n",
    "\n",
    "Reward function: $\\begin{equation}\n",
    "  r(X_n, X_{n+1}, A_n)=\\begin{cases}\n",
    "    100[X_n-X_{n+1}]^+ - 50a -100, & \\text{if $A_n > 0$}.\\\\\n",
    "    100[X_n-X_{n+1}]^+, & \\text{if $A_n = 0$}.\n",
    "  \\end{cases}\n",
    "\\end{equation}$\n",
    "\n",
    "representing the reward associated with the transition from state $X_n$ to state $X_{n+1}$ given action state $a$. If no delivery, i.e. $A_n = 0$, then no delivery cost or item cost associated with reward\n",
    "\n",
    "Choice of action states $a$ are only permitted to the extent that the current state space $s$ contains enough inventory to allow for such selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 states and actions\n",
    "\n",
    "states, actions = [i for i in range(5)], [i for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.86466472,  0.13533528,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.59399415,  0.27067057,  0.13533528,  0.        ,  0.        ],\n",
       "       [ 0.32332358,  0.27067057,  0.27067057,  0.13533528,  0.        ],\n",
       "       [ 0.14287654,  0.18044704,  0.27067057,  0.27067057,  0.13533528]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#poisson distribution of demand\n",
    "\n",
    "B=np.zeros((5,5))\n",
    "#i is the initial number of items\n",
    "for i in range(5):\n",
    "    #j is the new number after decay\n",
    "    for j in range(1,i+1):\n",
    "        #i-j decayed out of i, with lambda=4\n",
    "        prob=poisson.pmf(i-j,2)\n",
    "        B[j][i]=prob\n",
    "    B[0][i]=1-np.sum(B[:,i]) \n",
    "p = B.T\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[   0.,    0.,    0.,    0.,    0.],\n",
       "        [ 100.,    0.,    0.,    0.,    0.],\n",
       "        [ 200.,  100.,    0.,    0.,    0.],\n",
       "        [ 300.,  200.,  100.,    0.,    0.],\n",
       "        [ 400.,  300.,  200.,  100.,    0.]]),\n",
       " array([[   0.,    0.,    0.,    0.,    0.],\n",
       "        [ -50., -150., -150., -150., -150.],\n",
       "        [  50.,  -50., -150., -150., -150.],\n",
       "        [ 150.,   50.,  -50., -150., -150.],\n",
       "        [ 250.,  150.,   50.,  -50., -150.]]),\n",
       " array([[   0.,    0.,    0.,    0.,    0.],\n",
       "        [   0.,    0.,    0.,    0.,    0.],\n",
       "        [   0., -100., -200., -200., -200.],\n",
       "        [ 100.,    0., -100., -200., -200.],\n",
       "        [ 200.,  100.,    0., -100., -200.]]),\n",
       " array([[   0.,    0.,    0.,    0.,    0.],\n",
       "        [   0.,    0.,    0.,    0.,    0.],\n",
       "        [   0.,    0.,    0.,    0.,    0.],\n",
       "        [  50.,  -50., -150., -250., -250.],\n",
       "        [ 150.,   50.,  -50., -150., -250.]]),\n",
       " array([[   0.,    0.,    0.,    0.,    0.],\n",
       "        [   0.,    0.,    0.,    0.,    0.],\n",
       "        [   0.,    0.,    0.,    0.,    0.],\n",
       "        [   0.,    0.,    0.,    0.,    0.],\n",
       "        [ 100.,    0., -100., -200., -300.]])]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reward function matrix\n",
    "\n",
    "r = [np.zeros((5,5)) for i in range(5)]\n",
    "def reward(x,y,a):\n",
    "    if a > 0:\n",
    "        return 100*max(0,x-y) - 50*a - 100\n",
    "    else:\n",
    "        return 100*(max(0,x-y))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        for k in range(5):\n",
    "            if i > j:\n",
    "                r[i][j][k] = 0\n",
    "            else:\n",
    "                r[i][j][k] = reward(j,k,i)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 2, 3, 4], 1: [0, 1, 2, 3], 2: [0, 1, 2], 3: [0, 1], 4: [0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to create a subset of actions that you can take if you're in a given state\n",
    "#if you're in state 4, you can't buy any items (must take action 0)\n",
    "\n",
    "a_map = {i:[j for j in range(5-i)] for i in states}\n",
    "a_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192.48589899999999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test for state 4 > action 0 > reward computation\n",
    "\n",
    "test1 = np.array([ 0.14287654,  0.18044704,  0.27067057,  0.27067057,  0.13533528])\n",
    "test2 = np.array([ 400.,  300.,  200.,  100.,    0.])\n",
    "test2.dot(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-107.51410099999998"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test for state 0 > action 4 > reward computation\n",
    "\n",
    "test1 = np.array([ 0.14287654,  0.18044704,  0.27067057,  0.27067057,  0.13533528])\n",
    "test2 = np.array([ 100.,    0., -100., -200., -300.])\n",
    "test1.dot(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0.0,\n",
       "  -63.533528323661272,\n",
       "  -54.134113294645083,\n",
       "  -71.801754912951424,\n",
       "  -107.51410096280614],\n",
       " 1: [86.466471676338728,\n",
       "  -4.1341132946450792,\n",
       "  -21.801754912951431,\n",
       "  -57.51410096280614],\n",
       " 2: [145.86588670535491, 28.198245087048569, -7.5141009628061326],\n",
       " 3: [178.19824508704858, 42.485899037193867],\n",
       " 4: [192.48589903719386]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create reward vectors as conditional expectation of each action / state using\n",
    "#the map of possible states resulting from given actions\n",
    "\n",
    "#i.e. you were in state 3: you took action 0: expectation of reward = 178\n",
    "#you were in state 4: you took action 0: expectation of reward = 192\n",
    "\n",
    "#YOU START IN STATE 0, TAKE ACTION 4, END IN STATE 4 (TAKE EXPECTED VALUE HERE)\n",
    "\n",
    "#new\n",
    "exp_r = {}\n",
    "for i, j in a_map.items():\n",
    "    exp_r[i] = [r[k][i+k].dot(p[i+k]) for k in j]\n",
    "exp_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(iters, discount, verbose):\n",
    "    \n",
    "    policy = [np.zeros(5) for i in range(iters)]\n",
    "    v = np.array([i[0] for i in exp_r.values()])\n",
    "\n",
    "    if verbose == True:\n",
    "        print('############\\ninitial values:\\n',v,'\\n############')\n",
    "        \n",
    "    for i in range(iters):\n",
    "        v_temp = np.zeros(5)\n",
    "        for state in states:\n",
    "            rewards = {}\n",
    "            if verbose == True:\n",
    "                print('\\ncurrent state:', state, '\\ncurrent value:', v[state])\n",
    "            if verbose == True:\n",
    "                print('available actions:', a_map[state],'\\n')\n",
    "            \n",
    "            total = 0\n",
    "            for action in a_map[state]:\n",
    "                rewards[action] = exp_r[state][action] + (discount * v.dot(p[state + action]))\n",
    "\n",
    "            if verbose == True:\n",
    "                print('Actions/Rewards:\\n', rewards)\n",
    "            \n",
    "            reward_max = max(rewards.values())\n",
    "            v_temp[state] = reward_max\n",
    "\n",
    "            best_action = [x==reward_max for x in rewards.values()].index(True)\n",
    "            policy[i][state] = best_action\n",
    "            \n",
    "            if verbose == True:\n",
    "                print('### Optimal Action: ', best_action,'###\\n')\n",
    "\n",
    "        v = v_temp\n",
    "\n",
    "        \n",
    "        if verbose == True:\n",
    "            print('###############\\nvalue update:', v, '\\n###############')\n",
    "\n",
    "    return v, policy[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  [  867.37996584   922.00895931  1007.50141453  1088.19238994  1167.37996584] \n",
      "\n",
      "Policy:  [ 4.  0.  0.  0.  0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value, policy = value_iteration(25,.99, False)\n",
    "print('Value: ',value,'\\n')\n",
    "print('Policy: ',policy,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  [ 2481.18946473  2535.8184582   2621.31091342  2702.00188883  2781.18946473] \n",
      "\n",
      "Policy:  [ 4.  0.  0.  0.  0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value, policy = value_iteration(100,.99, False)\n",
    "print('Value: ',value,'\\n')\n",
    "print('Policy: ',policy,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  [ 3845.32903897  3899.95803244  3985.45048766  4066.14146306  4145.32903897] \n",
      "\n",
      "Policy:  [ 4.  0.  0.  0.  0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value, policy = value_iteration(400,.99, False)\n",
    "print('Value: ',value,'\\n')\n",
    "print('Policy: ',policy,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  [ 3915.50843168  3970.13742515  4055.62988037  4136.32085577  4215.50843168] \n",
      "\n",
      "Policy:  [ 4.  0.  0.  0.  0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value, policy = value_iteration(1000,.99, False)\n",
    "print('Value: ',value,'\\n')\n",
    "print('Policy: ',policy,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value:  [ 3915.67762067  3970.30661415  4055.79906936  4136.49004477  4215.67762067] \n",
      "\n",
      "Policy:  [ 4.  0.  0.  0.  0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "value, policy = value_iteration(10000,.99, False)\n",
    "print('Value: ',value,'\\n')\n",
    "print('Policy: ',policy,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "\n",
    "This originally didn't work for me in python, so I used the below commands/matrices in matlab and got these results:\n",
    "\n",
    "\n",
    "linprog(c',-A,-b)\n",
    "\n",
    "Optimal solution found.\n",
    "\n",
    "ans = \n",
    "\n",
    "1.0e+03 *\n",
    "\n",
    "3.9157\n",
    "3.9703\n",
    "4.0558\n",
    "4.1365\n",
    "4.2157\n",
    "\n",
    "\n",
    "This is consistent with the results from my value iteration in part a, but the linear program actually took significantly less iterations (8 vs over 1000) to converge\n",
    "\n",
    "\n",
    "However, I tried using a method other than simplex (not sure if this was ok but I really didn't have much of a choice). I ended up using an interior point method optimization in python and that seemed to work better.\n",
    "\n",
    "All of the code is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([i[0] for i in exp_r.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([1 for i in range(5)])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[   0.    ],\n",
       "        [ -63.5335],\n",
       "        [ -54.1341],\n",
       "        [ -71.8018],\n",
       "        [-107.5141],\n",
       "        [  86.4665],\n",
       "        [  -4.1341],\n",
       "        [ -21.8018],\n",
       "        [ -57.5141],\n",
       "        [-102.2488],\n",
       "        [ 145.8659],\n",
       "        [  28.1982],\n",
       "        [  -7.5141],\n",
       "        [ -52.2488],\n",
       "        [-102.2488],\n",
       "        [ 178.1982],\n",
       "        [  42.4859],\n",
       "        [  -2.2488],\n",
       "        [ -52.2488],\n",
       "        [-101.0458],\n",
       "        [ 192.4859],\n",
       "        [  47.7512],\n",
       "        [  -2.2488],\n",
       "        [ -51.0458],\n",
       "        [-100.3584]])"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = exp_r[0] + exp_r[1] + [-102.2488] + exp_r[2] \\\n",
    "+ [-52.2488,-102.2488] + exp_r[3] + [-2.2488,-52.2488,-101.0458,192.4859] \\\n",
    "+ [47.7512, -2.2488, -51.0458, -100.3584]\n",
    "b = [round(i,4) for i in b]\n",
    "b = np.matrix(b)\n",
    "b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01  , -0.    , -0.    , -0.    , -0.    ],\n",
       "       [ 0.144 , -0.134 , -0.    , -0.    , -0.    ],\n",
       "       [ 0.4119, -0.268 , -0.134 , -0.    , -0.    ],\n",
       "       [ 0.6799, -0.268 , -0.268 , -0.134 , -0.    ],\n",
       "       [ 0.8586, -0.1786, -0.268 , -0.268 , -0.134 ],\n",
       "       [-0.856 ,  0.866 ,  0.    ,  0.    ,  0.    ],\n",
       "       [-0.5881,  0.732 , -0.134 ,  0.    ,  0.    ],\n",
       "       [-0.3201,  0.732 , -0.268 , -0.134 ,  0.    ],\n",
       "       [-0.1414,  0.8214, -0.268 , -0.268 , -0.134 ],\n",
       "       [-0.1414,  0.8214, -0.268 , -0.268 , -0.134 ],\n",
       "       [-0.5881, -0.268 ,  0.866 ,  0.    ,  0.    ],\n",
       "       [-0.3201, -0.268 ,  0.732 , -0.134 ,  0.    ],\n",
       "       [-0.1414, -0.1786,  0.732 , -0.268 , -0.134 ],\n",
       "       [-0.1414, -0.1786,  0.732 , -0.268 , -0.134 ],\n",
       "       [-0.1414, -0.1786,  0.732 , -0.268 , -0.134 ],\n",
       "       [-0.3201, -0.268 , -0.268 ,  0.866 ,  0.    ],\n",
       "       [-0.1414, -0.1786, -0.268 ,  0.732 , -0.134 ],\n",
       "       [-0.1414, -0.1786, -0.268 ,  0.732 , -0.134 ],\n",
       "       [-0.1414, -0.1786, -0.268 ,  0.732 , -0.134 ],\n",
       "       [-0.1414, -0.1786, -0.268 ,  0.732 , -0.134 ],\n",
       "       [-0.1414, -0.1786, -0.268 , -0.268 ,  0.866 ],\n",
       "       [-0.1414, -0.1786, -0.268 , -0.268 ,  0.866 ],\n",
       "       [-0.1414, -0.1786, -0.268 , -0.268 ,  0.866 ],\n",
       "       [-0.1414, -0.1786, -0.268 , -0.268 ,  0.866 ],\n",
       "       [-0.1414, -0.1786, -0.268 , -0.268 ,  0.866 ]])"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.zeros((25,5))\n",
    "test[0:5], test[6:10], test[12:15], test[18:20], test[24:25] = \\\n",
    ".99*p, .99*p[1:5], .99*p[2:5], .99*p[3:5], .99*p[4:5]\n",
    "A = test.copy()\n",
    "for i in range(25):\n",
    "    for j in range(5):\n",
    "        if not A[i][0] == 0:\n",
    "            A[i][0] = round(1-A[i][0],4)\n",
    "            A[i][j] = round(A[i][j],4)\n",
    "\n",
    "A[0:5,1:5] = -1*A[0:5,1:5]\n",
    "A[5]=[-.856,.866,0,0,0]\n",
    "A[6]=[-.5881,.732,-.134,0,0]\n",
    "A[7]=[-.3201,.732,-.268,-.134,0]\n",
    "A[8]=[-.1414,.8214,-.268,-.268,-.134]\n",
    "A[9]=[-.1414,.8214,-.268,-.268,-.134]\n",
    "A[10]=[-.5881,-.268,.866,0,0]\n",
    "A[11]=[-.3201,-.268,.732,-.134,0]\n",
    "A[12]=[-.1414,-.1786,.732,-.268,-.134]\n",
    "A[13]=[-.1414,-.1786,.732,-.268,-.134]\n",
    "A[14]=[-.1414,-.1786,.732,-.268,-.134]\n",
    "A[15]=[-.3201,-.268,-.268,.866,0]\n",
    "A[16]=[-.1414,-.1786,-.268,.732,-.134]\n",
    "A[17]=[-.1414,-.1786,-.268,.732,-.134]\n",
    "A[18]=[-.1414,-.1786,-.268,.732,-.134]\n",
    "A[19]=[-.1414,-.1786,-.268,.732,-.134]\n",
    "A[20]=[-.1414,-.1786,-.268,-.268,.866]\n",
    "A[21]=[-.1414,-.1786,-.268,-.268,.866]\n",
    "A[22]=[-.1414,-.1786,-.268,-.268,.866]\n",
    "A[23]=[-.1414,-.1786,-.268,-.268,.866]\n",
    "A[24]=[-.1414,-.1786,-.268,-.268,.866]\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A dim: (25, 5) b dim: (25, 1) c dim: (5,)\n"
     ]
    }
   ],
   "source": [
    "print('A dim:', A.shape, 'b dim:',b.T.shape, 'c dim:',c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sp.optimize.linprog(c, A_ub=-A, b_ub=-b.T, method='interior-point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     con: array([], dtype=float64)\n",
       "     fun: 20365.011329067012\n",
       " message: 'Optimization terminated successfully.'\n",
       "     nit: 8\n",
       "   slack: array([  3.92980710e+01,   9.55329919e+01,   5.96328316e+01,\n",
       "         2.88583499e+01,   2.46692622e-08,  -1.15810508e-08,\n",
       "         6.40998396e+01,   3.33253580e+01,   4.46700809e+00,\n",
       "         4.92017081e+01,  -3.20517302e-08,   6.92255183e+01,\n",
       "         4.03671684e+01,   8.51018684e+01,   1.35101868e+02,\n",
       "        -3.87887837e-08,   7.11416501e+01,   1.15876350e+02,\n",
       "         1.65876350e+02,   2.14673350e+02,  -4.02672811e-08,\n",
       "         1.44734700e+02,   1.94734700e+02,   2.43531700e+02,\n",
       "         2.92844300e+02])\n",
       "  status: 0\n",
       " success: True\n",
       "       x: array([ 3929.80710052,  3984.27410858,  4070.17426892,  4150.94875059,\n",
       "        4229.80710046])"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3929.80710052,  3984.27410858,  4070.17426892,  4150.94875059,\n",
       "        4229.80710046])"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)\n",
    "\n",
    "$V(x) = \\max_T E_x[\\sum_{j=0}^{T-1} d(X_j) + r(X_T)]$\n",
    "\n",
    "or in in english, max(reward when stop (T=0), don't stop(T>0))\n",
    "\n",
    "$= max(r(X_0), E_x[d(x) + \\sum_{j=0}^{T-1} d(X_j) + r(X_T)])$\n",
    "\n",
    "$= max(r(X_0), d(x) + \\sum_{y \\in S}p(x,y)v(y))$\n",
    "\n",
    "which is basically an FTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)\n",
    "\n",
    "$min \\sum_x V(x)$\n",
    "\n",
    "$s.t.$\n",
    "\n",
    "$V(x) \\geq max(r(X_0), d(x) + \\sum_{y \\in S}p(x,y)v(y))\\ \\forall x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)\n",
    "\n",
    "This is the memoryless property at work\n",
    "\n",
    "$Exp\\ R_i \\sim Exp(\\lambda_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)\n",
    "\n",
    "We want the minimum amount of time that we'll have to wait to see a doctor\n",
    "\n",
    "$W = min_{1 \\leq i \\leq k} R_i \\sim Exp(\\sum_{i=0}^k \\lambda_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)\n",
    "\n",
    "the crux of the solution to this problem relies on the fact that the doctors are independent\n",
    "\n",
    "$P(R_1 < R_2) = \\int_{0}^{\\infty} P(t < R_2) dt$\n",
    "\n",
    "$= \\int_{0}^{\\infty} P(R_1 < R_2 | R_1 = t) \\lambda_1 exp(-\\lambda, t) dt$\n",
    "\n",
    "$= \\int_{0}^{\\infty} P(t < R_2 | R_1 = t) \\lambda_1 exp(-\\lambda, t) dt$\n",
    "\n",
    "$= \\int_{0}^{\\infty} P(t < R_2) \\lambda_1 exp(-\\lambda, t) dt$\n",
    "\n",
    "$= \\frac{\\lambda_i}{\\sum_{j=1}^k \\lambda_j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)\n",
    "\n",
    "we rely on independence here too\n",
    "\n",
    "$min_{j \\neq i} R_j \\sim Exp(\\sum_{j=1}^k \\lambda_j)$ is independent of $R_i \\sim Exp(\\lambda_i)$\n",
    "\n",
    "so if we want to solve for $P(R_i < min_{j \\neq i} R_j)$ we can use the same solution as in c\n",
    "\n",
    "$= \\frac{\\lambda_i}{\\sum_{j=1}^k \\lambda_j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e)\n",
    "\n",
    "we can compute the expected amount of time spent as the expected time spent conditioned on $R_i < min_{j \\neq i} R_j $\n",
    "\n",
    "$E[time] =  \\sum_{i=1}^k E[time|R_i < min_{j \\neq i} R_j] P(R_i < min_{j \\neq i} R_j )$\n",
    "\n",
    "$=\\sum_{i=1}^k (E[W | R_i < min_{j \\neq i} R_j] + E[T_i | R_i < min_{j \\neq i} R_j]) P(R_i < min_{j \\neq i} R_j )$\n",
    "\n",
    "$=\\sum_{i=1}^k (E[W | R_i < min_{j \\neq i} R_j] + E[T_i]) P(R_i < min_{j \\neq i} R_j )$\n",
    "\n",
    "$= \\sum_{i=1}^k (E[W | R_i < min_{j \\neq i} R_j] + \\frac{1}{\\lambda}) P(R_i < min_{j \\neq i} R_j )$\n",
    "\n",
    "$=(\\frac{E[R_i I(R_i < min_{j \\neq i} R_j)]}{P(R_i < min_{j \\neq i} R_j)} + \\frac{1}{\\lambda} )P(R_i < min_{j \\neq i} R_j )$\n",
    "\n",
    "where we only want to integrate the region where $I(R_i < min_{j \\neq i} R_j)$\n",
    "\n",
    "and the probabilities in the demoninator of the left portion of the equation cancel the probability in the right\n",
    "\n",
    "$= \\int_{0}^{\\infty}(\\int_{0}^{x} y \\lambda_j exp(\\lambda_i y) dy) \\lambda_j exp(-\\sum_{j\\neq i} \\lambda_j x)dx * \\frac{1}{\\lambda_i}$\n",
    "\n",
    "with the inner integral being the PDF of $R_i$\n",
    "\n",
    "and $ \\int_{0}^{\\infty}\\lambda_j exp(-\\sum_{j\\neq i} \\lambda_j x)dx = \\frac{\\lambda_i}{\\lambda_i + \\lambda_j}$\n",
    "\n",
    "\n",
    "$= Exp(\\lambda_i) \\frac{\\lambda_i}{\\lambda_i + \\lambda_j}\\frac{1}{\\lambda_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)\n",
    "\n",
    "$Y_1 \\sim exp(\\lambda)$\n",
    "\n",
    "$Y_1 \\sim exp(\\mu)$\n",
    "\n",
    "such that $P(Y_1 > y, Y_2 > y) = exp(-y \\lambda)exp(-y \\mu) = exp(-y(\\lambda + \\mu))$\n",
    "\n",
    "$min(Y_1, Y_2) \\sim exp(\\lambda + \\mu) = E[(Y_1,Y_2)] = \\frac{1}{\\lambda+\\mu}$\n",
    "\n",
    "\n",
    "$\\begin{equation}\n",
    "  P_{ij}=\\begin{cases}\n",
    "    \\frac{\\mu}{\\lambda+\\mu}, & \\text{if $j = i - 1$}.\\\\\n",
    "    \\frac{\\lambda}{\\lambda+\\mu}, & \\text{if $j = i + 1$}.\n",
    "  \\end{cases}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)\n",
    "\n",
    "for $i \\geq 0$\n",
    "\n",
    "$E_i[T_j] = \\frac{1}{\\lambda+\\mu} + E_{i-1}[T_j \\frac{\\mu}{\\lambda+\\mu}] + E_{i+1}[T_j \\frac{\\lambda}{\\lambda+\\mu}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)\n",
    "\n",
    "$E_0[T_1] = \\frac{1}{\\lambda}$\n",
    "\n",
    "whereas $E_{12} = E_1[T_2]$ or $E_{ij} = E_i[T_j]$\n",
    "\n",
    "so $(\\lambda + \\mu)E_{12} = 1 + (E_{01} + E_{12}$\n",
    "\n",
    "and\n",
    "\n",
    "$\\lambda E_{12} = 1 + \\frac{\\mu}{\\lambda}$\n",
    "\n",
    "$= E_{12} = \\frac{1}{\\lambda}[1+\\frac{\\mu}{\\lambda}^1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can prove this further by induction\n",
    "\n",
    "we know that $E_{i, i+1} = \\frac{1}{\\lambda}[\\sum_{k=0}^i \\frac{\\mu}{\\lambda}^k]$ for i = 0, i = 1\n",
    "\n",
    "$E_{j, j+1} = \\frac{1}{\\lambda + \\mu} + \\frac{\\mu}{\\lambda + \\mu} E_{j-1, j+1}$\n",
    "\n",
    "$(\\lambda + \\mu)E_{j, j+1} = 1 + \\mu(E_{j-1, j}+E_{j, j+1})$\n",
    "\n",
    "$\\lambda E_{j, j+1} = 1 + \\mu E_{j-1, j}$\n",
    "\n",
    "$E_{j, j+1} = \\frac{1}{\\lambda} + \\frac{\\mu}{\\lambda} E_{j-1, j}$\n",
    "\n",
    "$ = \\frac{1}{\\lambda} + \\frac{\\mu}{\\lambda}\\frac{1}{\\lambda}\\sum_{k=0}^{j-1}\\frac{\\mu}{\\lambda}^k$\n",
    "\n",
    "$ = \\frac{1}{\\lambda} + [{\\lambda}\\sum_{k=0}^{j-1}\\frac{\\mu}{\\lambda}^k]$\n",
    "\n",
    "which concludes the proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)\n",
    "\n",
    "we can solve for the expected amount of time by solving into systems of linear equations given the expectations that we found earlier\n",
    "\n",
    "$S_j = E_{0, j}$\n",
    "\n",
    "such that $S_j = E_{0,1} + E_{0,1} + ... E_{j-1,j}$\n",
    "\n",
    "= $1/2 + 1/2(3/2)$\n",
    "\n",
    "= $1/1 + 1/2(3/2) + 1/2(3/2)^2$\n",
    "\n",
    "so $S_{j+1} = (3/2)S_j + 1/2(j+1)$\n",
    "\n",
    "$2S_{j+1} = 3S_j + j + 1$\n",
    "\n",
    "thus $2X = 3; X = 3/2$\n",
    "\n",
    "$S_j = a(3/2)^j + bj + c$\n",
    "\n",
    "$S_0 = 0; 0 = a + c$\n",
    "\n",
    "$S_1 = 1/2; 1/2 = 3/2a + b + c$\n",
    "\n",
    "$S_2 = 7/4; 7/4 = 9/4 + 2b + c$\n",
    "\n",
    "solving yields a = 3, b = -1, c = -3\n",
    "\n",
    "$S_j = 3(3/2)^j - n - 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
